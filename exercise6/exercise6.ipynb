{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd04b5be0c7d8816b0411dd8381c01b6ac4b538687487d40264816f7c3f94b5666c",
   "display_name": "Python 3.7.9 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Exercise 9"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### (a)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The primal problem is given as:\n",
    "$ min_{w \\in \\mathbb(R)^d, \\epsilon \\in \\mathbb(R)^n} \\frac{1}{2}\\Vert w \\Vert^2 + \\frac{C}{n} \\sum_i \\epsilon_i$, subject to: $Y_i (\\langle w, X_i \\rangle ) \\geq 1-\\epsilon , \\epsilon_i \\geq 0$.\n",
    "\n",
    "\n",
    "The lagrangian of the problem is : $\\frac{1}{2}\\Vert w \\Vert^2 + \\frac{C}{n} \\sum_i \\epsilon_i + \\sum_i \\alpha_i (1 - \\epsilon_i - Y_i \\langle w, X_i \\rangle ) - \\sum_i \\beta_i \\epsilon_i$\n",
    "\n",
    "Now take the derivative:\n",
    "\\begin{align}\n",
    "& \\nabla_w \\frac{1}{2}\\Vert w \\Vert^2 + \\frac{C}{n} \\sum_i \\epsilon_i + \\sum_i \\alpha_i (1 - \\epsilon_i - Y_i \\langle w, X_i \\rangle ) - \\sum_i \\beta_i \\epsilon_i \\\\\n",
    "&= w - \\sum_i \\alpha_i Y_i X_i\\\\\n",
    "& \\Rightarrow w=\\sum_i \\alpha_i Y_i X_i\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "& \\frac{\\partial}{\\partial \\epsilon_i} \\frac{1}{2}\\Vert w \\Vert^2 + \\frac{C}{n} \\sum_i \\epsilon_i + \\sum_i \\alpha_i (1 - \\epsilon_i - Y_i \\langle w, X_i \\rangle ) - \\sum_i \\beta_i \\epsilon_i\\\\\n",
    "& = \\frac{C}{n} - \\alpha_i - \\beta_i \\\\\n",
    "\\end{align}\n",
    "\n",
    "By setting the gradient of $\\epsilon$ to 0 we can use this equation to get rid of beta, as $\\beta_i = \\frac{C}{n} - \\alpha_i$, this imposed the constrain $\\alpha_i < \\frac{C}{n} $ due to the positivity of $\\beta$.\n",
    "\n",
    "No substitution in $L$ we get:\n",
    "\\begin{align}\n",
    "& \\frac{1}{2} \\Vert \\sum_i \\alpha_i Y_i X_i \\Vert^2 + \\frac{C}{n} \\sum_i \\epsilon_i \\sum_i \\alpha_i (1 - \\epsilon_i - Y_i \\langle \\sum_i \\alpha_i Y_i X_i, X_i \\rangle ) - \\sum_i (\\frac{C}{n} - \\alpha_i) \\epsilon_i\\\\\n",
    "& \\frac{1}{2} \\Vert \\sum_i \\alpha_i Y_i X_i \\Vert^2 + \\sum_i (\\frac{C}{n} - \\alpha_i) \\epsilon_i \\sum_i \\alpha_i (1 - Y_i \\langle \\sum_i \\alpha_i Y_i X_i, X_i \\rangle ) - \\sum_i (\\frac{C}{n} - \\alpha_i) \\epsilon_i\\\\\n",
    "&= \\frac{1}{2} \\Vert \\sum_i \\alpha_i Y_i X_i \\Vert^2 + \\sum_i \\alpha_i  - \\sum_i \\alpha_i Y_i \\langle \\sum_i \\alpha_i Y_i X_i, X_i \\rangle)\\\\\n",
    "&=  \\sum_i \\alpha_i  - \\frac{1}{2} \\Vert \\sum_i \\alpha_i Y_i X_i \\Vert^2\\\\\n",
    "&=  \\sum_i \\alpha_i  - \\frac{1}{2} \\sum_{i,j} \\alpha_i \\alpha_j y_i y_j \\langle x_i, x_j \\rangle\\\\\n",
    "\\end{align}\n",
    "\n",
    "Or dual problem is therefore given as:\n",
    "$\\max_{\\alpha \\in \\mathbb{R}^n} \\sum_i \\alpha_i  - \\frac{1}{2} \\sum_{i,j} \\alpha_i \\alpha_j y_i y_j \\langle x_i, x_j \\rangle$, subject to $0\\leq \\alpha_i \\leq \\frac{C}{n}$.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### (b)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "1.\n",
    "The derivative is given by:\n",
    "\\begin{align}\n",
    "\\frac{\\partial}{\\partial \\alpha_r} \\Psi(..., \\alpha_r, ...)\n",
    "&= \\frac{\\partial}{\\partial \\alpha_r} \\sum_i \\alpha_i - \\frac{1}{2} \\sum_{i,j} \\alpha_i \\alpha_j Y_i Y_j \\langle x_i, x_j \\rangle \\\\\n",
    "&=  1 - \\frac{\\partial}{\\partial \\alpha_r} \\frac{1}{2} \\sum_{i,j} \\alpha_i \\alpha_j Y_i Y_j \\langle x_i, x_j \\rangle \\\\\n",
    "&=  1 - \\alpha_r Y_r^2 \\langle x_r, x_r \\rangle - \\frac{\\partial}{\\partial \\alpha_r} \\frac{1}{2} \\sum_{i,j\\neq i} \\alpha_i \\alpha_j Y_i Y_j \\langle x_i, x_j \\rangle \\\\\n",
    "&=  1 - \\alpha_r Y_r^2 \\langle x_r, x_r \\rangle -  \\frac{1}{2} \\sum_{j\\neq r}  \\alpha_j Y_r Y_j \\langle x_r, x_j \\rangle \\\\\n",
    "\\end{align}\n",
    "\n",
    "Set to 0:\n",
    "\n",
    "\\begin{align}\n",
    "\\alpha_r Y_r^2 \\langle x_r, x_r \\rangle &= 1 - \\frac{1}{2} \\sum_{j\\neq r}  \\alpha_j Y_r Y_j \\langle x_r, x_j \\rangle\\\\\n",
    "\\alpha_r  &= 1 - \\frac{1}{2} \\sum_{j\\neq r}  \\alpha_j Y_r Y_j \\langle x_r, x_j \\rangle / Y_r^2 \\langle x_r, x_r \\rangle\\\\\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "If $ 1 - \\frac{1}{2} \\sum_{j\\neq r}  \\alpha_j Y_r Y_j \\langle x_r, x_j \\rangle < 0 \\Rightarrow \\alpha_r < 0$, as problem concave, best solution is given by 0. Similarly other way round\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "2.\n",
    "The KKT condition is given by $\\alpha_i (1-\\epsilon_i - Y_i \\langle w, X_i \\rangle )=0$.\n",
    "- If $\\alpha_i = 0$, this means that the point is outisde the margin, therefore condition holds.\n",
    "- If $\\alpha_i=1$, point is on margin, therefore 1.\n",
    "- If $\\alpha_i = \\frac{C}{n}$, means point is inside margin, therefore smaller 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## (c)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CoordinateDescentSVM(Xtrain, Ytrain, C, Xtest, Ytest):\n",
    "    ''' compute the solution of linear SVM\n",
    "    Xtrain, Ytrain: training set\n",
    "    Xtest, Ytest: test set (only to monitor test error)\n",
    "    C: error parameter\n",
    "\n",
    "    w: weights linear SVM\n",
    "    TrainError, TestError: training and test errors over iterations\n",
    "    '''\n",
    "    n = Xtrain.shape[0]\n",
    "    alpha = np.zeros([n, 1]) # initialize dual variables\n",
    "    w = Xtrain.T @ (Ytrain * alpha) # initialize primal variables\n",
    "\n",
    "    counter = 0\n",
    "    converged = False\n",
    "    eps = 1e-3\n",
    "    TrainError, TestError = [], []\n",
    "    \n",
    "    indices = np.array(list(range(n)))\n",
    "    # print(np.where(indices!=1))\n",
    "\n",
    "    while not converged:\n",
    "        # select coordinate to update\n",
    "        r = counter % n\n",
    "\n",
    "        r_index = np.where(indices!=r)\n",
    "\n",
    "        alpha_r = (1- alpha[r]* Xtrain[r,:] @ Xtrain[r,:] - 0.5 * np.sum(alpha[r_index] * Ytrain[r_index] * Ytrain[r] * np.expand_dims(np.squeeze(Xtrain[r_index, :]) @ Xtrain[r, :].T, axis=1)))#/(Xtrain[:,r] @ Xtrain[:,r])\n",
    "        # solve the subproblem for coordinate r without any constraints\n",
    "        # alpha_r = (1 - np.sum([alpha[index] * Ytrain[index] * Ytrain[r] * (Xtrain[:,index].T @ Xtrain[:,r]) for index in indices[indices!=r]]))/(Xtrain[:,r].T @ Xtrain[:,r])\n",
    "\n",
    "        # project the solution to the interval [0, C / n]\n",
    "        alpha[r] = np.maximum(0.0, np.minimum(alpha_r, C/n))\n",
    "\n",
    "        # monitor the progress of the method computing the dual\n",
    "        # objective DualObj\n",
    "\n",
    "        if (counter + 1) % 100 == 0:\n",
    "            DualObj = np.sum(alpha) - 0.5 * np.sum(np.outer(alpha, alpha) * np.outer(Ytrain, Ytrain) * cdist(Xtrain, Xtrain, lambda a,b: a.T @ b))\n",
    "            print('iteration={} dual obj={:.3f}'.format(\n",
    "                counter + 1, DualObj))\n",
    "\n",
    "        # compute the training and test error with the current iterate alpha\n",
    "        w = np.expand_dims(np.sum(alpha * Ytrain * Xtrain,   axis=0), axis=1)\n",
    "        TrainError.append(np.sum(np.sign(Xtrain @ w) != Ytrain)/n)\n",
    "        TestError.append(np.sum(np.sign(Xtest @ w) != Ytest)/Xtest.shape[0])\n",
    "        #print(f\"Train accuracy in epoch {counter + 1}: {TrainError}\")\n",
    "\n",
    "        # if the KKT conditions are satisfied up to the tolerance eps by the\n",
    "        # the current iterate alpha then set converged = True\n",
    "        converged = np.all(Ytrain *(Xtrain @ w) > 1-eps)\n",
    "        counter += 1\n",
    "\n",
    "        # if counter >300:\n",
    "        #     converged = True\n",
    "        \n",
    "    # compute the primal solution w from alpha\n",
    "    # FILL IN\n",
    "\n",
    "    # show final dual objective\n",
    "    print('final iteration={} dual obj={:.3f}'.format(counter, DualObj))\n",
    "\n",
    "    return w, TrainError, TestError\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"digits01.npy\", allow_pickle=True).item()\n",
    "X_train = data[\"Xtrain\"]\n",
    "Y_train = data[\"Ytrain\"]\n",
    "X_test = data[\"Xtest\"]\n",
    "Y_test = data[\"Ytest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iteration=100 dual obj=0.499\n",
      "iteration=200 dual obj=0.998\n",
      "iteration=300 dual obj=1.495\n",
      "iteration=400 dual obj=1.991\n",
      "iteration=500 dual obj=2.486\n",
      "iteration=600 dual obj=2.979\n",
      "iteration=700 dual obj=3.472\n",
      "iteration=800 dual obj=3.963\n",
      "iteration=900 dual obj=4.453\n",
      "iteration=1000 dual obj=4.942\n",
      "iteration=1100 dual obj=5.431\n",
      "iteration=1200 dual obj=5.917\n",
      "iteration=1300 dual obj=6.403\n",
      "iteration=1400 dual obj=6.887\n",
      "iteration=1500 dual obj=7.369\n",
      "iteration=1600 dual obj=7.853\n",
      "iteration=1700 dual obj=8.335\n",
      "iteration=1800 dual obj=8.814\n",
      "iteration=1900 dual obj=9.290\n",
      "iteration=2000 dual obj=9.768\n",
      "iteration=2100 dual obj=9.768\n",
      "iteration=2200 dual obj=9.768\n",
      "iteration=2300 dual obj=9.768\n",
      "iteration=2400 dual obj=9.768\n",
      "iteration=2500 dual obj=9.768\n",
      "iteration=2600 dual obj=9.768\n",
      "iteration=2700 dual obj=9.768\n",
      "iteration=2800 dual obj=9.768\n",
      "iteration=2900 dual obj=9.768\n",
      "iteration=3000 dual obj=9.768\n",
      "iteration=3100 dual obj=9.768\n",
      "iteration=3200 dual obj=9.768\n",
      "iteration=3300 dual obj=9.768\n",
      "iteration=3400 dual obj=9.768\n",
      "iteration=3500 dual obj=9.768\n",
      "iteration=3600 dual obj=9.768\n",
      "iteration=3700 dual obj=9.768\n",
      "iteration=3800 dual obj=9.768\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a32b4a9c310d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCoordinateDescentSVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0maxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-e3b2395a9882>\u001b[0m in \u001b[0;36mCoordinateDescentSVM\u001b[1;34m(Xtrain, Ytrain, C, Xtest, Ytest)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mDualObj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m             print('iteration={} dual obj={:.3f}'.format(\n\u001b[0;32m     41\u001b[0m                 counter + 1, DualObj))\n",
      "\u001b[1;32mC:\\Eigene Programme\\Anaconda\\lib\\site-packages\\scipy\\spatial\\distance.py\u001b[0m in \u001b[0;36mcdist\u001b[1;34m(XA, XB, metric, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2755\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2756\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2757\u001b[1;33m                 \u001b[0mdm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXB\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2759\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "C_list = [10, 100]#, 200, 500]\n",
    "fig, axs = plt.subplots(1,4)\n",
    "for index, C in enumerate(C_list):\n",
    "    w, train_error, test_error = CoordinateDescentSVM(X_train, Y_train, C,  X_test, Y_test)\n",
    "    X = list(range(len(train_error)))\n",
    "    axs[index].plot(X, train_error)\n",
    "    axs[index].plot(X, test_error)\n",
    "    axs[index].set_xscale(\"log\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
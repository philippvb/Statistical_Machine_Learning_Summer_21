{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Machine Learning Exercise Sheet 8\r\n",
    "- Laura Haege\r\n",
    "- Philipp Noel von Bachmann, Matrikelnummer: 4116220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"DataFeatSel.npy\", allow_pickle=True).item()\n",
    "X_train = data[\"Xtrain\"]\n",
    "Y_train = data[\"Ytrain\"]\n",
    "X_test = data[\"Xtest\"]\n",
    "Y_test = data[\"Ytest\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y):\n",
    "    w = cho_solve(cho_factor(X.T @ X), X.T @ y)\n",
    "    return w, X @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss(y_pred, y):\r\n",
    "    return 0.5*np.sum(np.abs(y - np.sign(y_pred)))/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossValidation(X, Y, k=5, use_tqdm=True):\r\n",
    "    min_loss = np.inf\r\n",
    "    min_mask = []\r\n",
    "\r\n",
    "    X_split = np.array(np.array_split(X, k))\r\n",
    "    Y_split = np.array(np.array_split(Y, k))\r\n",
    "\r\n",
    "    masks = list(itertools.product([True, False], repeat=X.shape[1]))[:-1]\r\n",
    "    if use_tqdm:\r\n",
    "        masks = tqdm(masks)\r\n",
    "    for m in masks:\r\n",
    "        # compute k-fold cross validation\r\n",
    "        validation_loss = []\r\n",
    "        for i in range(k):\r\n",
    "            x_train = np.concatenate(np.delete(X_split, i, axis=0))[:, m] # add mask\r\n",
    "            y_train = np.concatenate(np.delete(Y_split, i, axis=0))\r\n",
    "            x_val = X_split[i][:, m] # add mask\r\n",
    "            y_val = Y_split[i]\r\n",
    "            w, x_pred = train(x_train, y_train)\r\n",
    "            validation_loss.append(Loss(x_val @ w, y_val))\r\n",
    "        # average over all losses and store\r\n",
    "        validation_loss = np.mean(validation_loss)\r\n",
    "\r\n",
    "        # check if smaller\r\n",
    "        if validation_loss < min_loss:\r\n",
    "            min_loss = validation_loss\r\n",
    "            min_mask = [m]\r\n",
    "        elif validation_loss == min_loss:\r\n",
    "            min_mask.append(m)\r\n",
    "\r\n",
    "    # find the ones with the least amount of features\r\n",
    "    feature_size = list(map(lambda x: np.sum(x), min_mask))\r\n",
    "    min_index = np.where(feature_size == np.min(feature_size))[0]\r\n",
    "    return np.array(min_mask)[min_index], min_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32767/32767 [00:20<00:00, 1637.99it/s]\n"
     ]
    }
   ],
   "source": [
    "mask, min_loss =  CrossValidation(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One min feature mask is/subset: [False False False  True False False False False  True  True False False\n",
      " False False False]\n",
      "The associated training loss is 0.2\n",
      "One min feature mask is/subset: [False False False  True False False False False False  True  True False\n",
      " False False False]\n",
      "The associated training loss is 0.2\n"
     ]
    }
   ],
   "source": [
    "# train on full set\r\n",
    "weights = []\r\n",
    "for m in mask:\r\n",
    "    print(f\"One min feature mask is/subset: {m}\")\r\n",
    "    w, x_pred = train(X_train[:, m], Y_train)\r\n",
    "    weights.append(w)\r\n",
    "    print(f\"The associated training loss is {Loss(x_pred, Y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One min feature mask/subset is: [False False False  True False False False False  True  True False False\n",
      " False False False]\n",
      "The associated test loss is 0.497\n",
      "One min feature mask/subset is: [False False False  True False False False False False  True  True False\n",
      " False False False]\n",
      "The associated test loss is 0.502\n"
     ]
    }
   ],
   "source": [
    "# testing on new data\r\n",
    "for m, w in zip(mask, weights):\r\n",
    "    print(f\"One min feature mask/subset is: {m}\")\r\n",
    "    print(f\"The associated test loss is {Loss(X_test[:, m] @ w, Y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error on the test set significantly is higher than on the training set. This can have several reasons:\r\n",
    "- Overfitting to the training set (unlikely with small amout of features but for example more features in truth relate to the classification than the training set suggests)\r\n",
    "- The training set and the test set come from different distributions and just don't belong together.\r\n",
    "- The labels are independent of the features, and we were just \"lucky\" that these features explained the training set well.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference probably has to do with the classifier, because we could get a small error just with a subset of features. However if the labels are independent of features, then both the classifier and feature selection are not the porblem but rather the prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would probably tell the biologists that they should look back at their dataset and make sure the data was generated correctly and the model is reasonable to solve the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Permutation_Test(X, y, alpha=0.05, n_samples=1000):\r\n",
    "    t_pis = []\r\n",
    "    # the baseline error is given as:\r\n",
    "    _, T = CrossValidation(X, y, use_tqdm=False)\r\n",
    "    print(f\"The Cross Validation error of the Baseline is {T}\\n\")\r\n",
    "\r\n",
    "    for i in tqdm(range(n_samples)):\r\n",
    "        random_permutation = np.random.permutation(y.shape[0])\r\n",
    "        y_perm = y[random_permutation]\r\n",
    "        _, T_pi = CrossValidation(X, y_perm, use_tqdm=False)\r\n",
    "        t_pis.append(T_pi)\r\n",
    "\r\n",
    "    t_pis = np.array(t_pis)\r\n",
    "    p = np.sum(t_pis <= T)/t_pis.shape[0]\r\n",
    "    print(f\"\\nThe result of th permutation test is that X and Y are {'in' if p > alpha else ''}dependent.\")\r\n",
    "    print(\"The p value is: \", p)\r\n",
    "    print(f\"The mean cross validation error is: {np.mean(t_pis)}\")\r\n",
    "    return t_pis\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We measure the cross validation error of the base classifier: 0.493. If Y is dependent on the X, this would mean that a permuted assignment of Y would lead to a worse error. Therefore we reject the test if more than $1 - \\alpha$ percent of the permuted losses lie above 0.493."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cross Validation error of the Baseline is 0.493\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:54<00:00, 18.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The result of th permutation test is that X and Y are independent.\n",
      "The p value is:  0.986\n",
      "The mean cross validation error is: 0.46929200000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test[:, :6]\r\n",
    "result = Permutation_Test(X_new, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the test imply that indeed the labels are independent of the features. This implies for 14. that the features we learned we just randomly good for the training dataset, but captured no underlying structure of the actual data generating process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\r\n",
    "bins = np.linspace(0.4, 0.55, 50)\r\n",
    "plt.hist(result, bins=bins);"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4b5be0c7d8816b0411dd8381c01b6ac4b538687487d40264816f7c3f94b5666c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}